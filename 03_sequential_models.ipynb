{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model, load_model\n",
    "from keras import initializers, regularizers, constraints\n",
    "from keras.regularizers import l2\n",
    "from keras.layers import Dense, Embedding, Input, concatenate, Flatten, Layer\n",
    "from keras.layers import LSTM, Bidirectional, GlobalMaxPool1D, Dropout, Conv1D, MaxPool1D, BatchNormalization\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, re, pickle\n",
    "import spacy\n",
    "from spacy.tokens.doc import Doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 3)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('data/labeledTrainData.tsv', sep='\\t')\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 2)\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv('data/testData.tsv', sep='\\t')\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_FEATURES = 25000\n",
    "MAX_LEN = 350"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_sentences_train = train['review'].fillna(\"UNKNOWN\").values.tolist()\n",
    "list_sentences_test = test['review'].fillna(\"UNKNOWN\").values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = text.Tokenizer(num_words=MAX_FEATURES)\n",
    "tokenizer.fit_on_texts(list_sentences_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_tokenized_train = tokenizer.texts_to_sequences(list_sentences_train)\n",
    "list_tokenized_test = tokenizer.texts_to_sequences(list_sentences_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sequence.pad_sequences(list_tokenized_train, maxlen=MAX_LEN)\n",
    "X_test = sequence.pad_sequences(list_tokenized_test, maxlen=MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train['sentiment'].values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N_CLASSES = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Model - No External Knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    EMBED_SIZE = 128\n",
    "    input_sequence = Input(shape=(MAX_LEN, ))\n",
    "    x = Embedding(input_dim=MAX_FEATURES, output_dim=EMBED_SIZE)(input_sequence)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Conv1D(filters=64, kernel_size=2, padding='same')(x)\n",
    "    x = Bidirectional(LSTM(32,\n",
    "                           return_sequences=True,\n",
    "                           kernel_regularizer=l2(0.0001)))(x)\n",
    "    x = GlobalMaxPool1D()(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(32, activation=\"elu\", kernel_regularizer=l2(0.0001))(x)\n",
    "    prediction = Dense(N_CLASSES, activation=\"sigmoid\")(x)\n",
    "    \n",
    "    model = Model(inputs=input_sequence, outputs=prediction)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "\n",
    "BATCH_SIZE = 512\n",
    "EPOCHS = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FILE_PATH = \"models/keras_model_weights.hdf5\"\n",
    "checkpoint = ModelCheckpoint(FILE_PATH, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=5)\n",
    "callbacks_list = [checkpoint, early]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         (None, 350)               0         \n",
      "_________________________________________________________________\n",
      "embedding_9 (Embedding)      (None, 350, 128)          3200000   \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 350, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 350, 64)           16448     \n",
      "_________________________________________________________________\n",
      "bidirectional_9 (Bidirection (None, 350, 64)           24832     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_4 (Glob (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 3,243,649\n",
      "Trainable params: 3,243,521\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"719pt\" viewBox=\"0.00 0.00 554.00 719.00\" width=\"554pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 715)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" points=\"-4,4 -4,-715 550,-715 550,4 -4,4\" stroke=\"transparent\"/>\n",
       "<!-- 139874067652736 -->\n",
       "<g class=\"node\" id=\"node1\">\n",
       "<title>139874067652736</title>\n",
       "<polygon fill=\"none\" points=\"108.5,-664.5 108.5,-710.5 437.5,-710.5 437.5,-664.5 108.5,-664.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"188.5\" y=\"-683.8\">input_9: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"268.5,-664.5 268.5,-710.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"302.5\" y=\"-695.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"268.5,-687.5 336.5,-687.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"302.5\" y=\"-672.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"336.5,-664.5 336.5,-710.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"387\" y=\"-695.3\">(None, 350)</text>\n",
       "<polyline fill=\"none\" points=\"336.5,-687.5 437.5,-687.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"387\" y=\"-672.3\">(None, 350)</text>\n",
       "</g>\n",
       "<!-- 139874067653296 -->\n",
       "<g class=\"node\" id=\"node2\">\n",
       "<title>139874067653296</title>\n",
       "<polygon fill=\"none\" points=\"69,-581.5 69,-627.5 477,-627.5 477,-581.5 69,-581.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"170.5\" y=\"-600.8\">embedding_9: Embedding</text>\n",
       "<polyline fill=\"none\" points=\"272,-581.5 272,-627.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"306\" y=\"-612.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"272,-604.5 340,-604.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"306\" y=\"-589.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"340,-581.5 340,-627.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"408.5\" y=\"-612.3\">(None, 350)</text>\n",
       "<polyline fill=\"none\" points=\"340,-604.5 477,-604.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"408.5\" y=\"-589.3\">(None, 350, 128)</text>\n",
       "</g>\n",
       "<!-- 139874067652736&#45;&gt;139874067653296 -->\n",
       "<g class=\"edge\" id=\"edge1\">\n",
       "<title>139874067652736-&gt;139874067653296</title>\n",
       "<path d=\"M273,-664.3799C273,-656.1745 273,-646.7679 273,-637.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"276.5001,-637.784 273,-627.784 269.5001,-637.784 276.5001,-637.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139874067594152 -->\n",
       "<g class=\"node\" id=\"node3\">\n",
       "<title>139874067594152</title>\n",
       "<polygon fill=\"none\" points=\"92,-498.5 92,-544.5 454,-544.5 454,-498.5 92,-498.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"170.5\" y=\"-517.8\">dropout_7: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"249,-498.5 249,-544.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"283\" y=\"-529.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"249,-521.5 317,-521.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"283\" y=\"-506.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"317,-498.5 317,-544.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"385.5\" y=\"-529.3\">(None, 350, 128)</text>\n",
       "<polyline fill=\"none\" points=\"317,-521.5 454,-521.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"385.5\" y=\"-506.3\">(None, 350, 128)</text>\n",
       "</g>\n",
       "<!-- 139874067653296&#45;&gt;139874067594152 -->\n",
       "<g class=\"edge\" id=\"edge2\">\n",
       "<title>139874067653296-&gt;139874067594152</title>\n",
       "<path d=\"M273,-581.3799C273,-573.1745 273,-563.7679 273,-554.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"276.5001,-554.784 273,-544.784 269.5001,-554.784 276.5001,-554.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139874067593368 -->\n",
       "<g class=\"node\" id=\"node4\">\n",
       "<title>139874067593368</title>\n",
       "<polygon fill=\"none\" points=\"95,-415.5 95,-461.5 451,-461.5 451,-415.5 95,-415.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"170.5\" y=\"-434.8\">conv1d_3: Conv1D</text>\n",
       "<polyline fill=\"none\" points=\"246,-415.5 246,-461.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"280\" y=\"-446.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"246,-438.5 314,-438.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"280\" y=\"-423.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"314,-415.5 314,-461.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"382.5\" y=\"-446.3\">(None, 350, 128)</text>\n",
       "<polyline fill=\"none\" points=\"314,-438.5 451,-438.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"382.5\" y=\"-423.3\">(None, 350, 64)</text>\n",
       "</g>\n",
       "<!-- 139874067594152&#45;&gt;139874067593368 -->\n",
       "<g class=\"edge\" id=\"edge3\">\n",
       "<title>139874067594152-&gt;139874067593368</title>\n",
       "<path d=\"M273,-498.3799C273,-490.1745 273,-480.7679 273,-471.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"276.5001,-471.784 273,-461.784 269.5001,-471.784 276.5001,-471.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139874067065432 -->\n",
       "<g class=\"node\" id=\"node5\">\n",
       "<title>139874067065432</title>\n",
       "<polygon fill=\"none\" points=\"6,-332.5 6,-378.5 540,-378.5 540,-332.5 6,-332.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"175\" y=\"-351.8\">bidirectional_9(lstm_9): Bidirectional(LSTM)</text>\n",
       "<polyline fill=\"none\" points=\"344,-332.5 344,-378.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"378\" y=\"-363.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"344,-355.5 412,-355.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"378\" y=\"-340.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"412,-332.5 412,-378.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"476\" y=\"-363.3\">(None, 350, 64)</text>\n",
       "<polyline fill=\"none\" points=\"412,-355.5 540,-355.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"476\" y=\"-340.3\">(None, 350, 64)</text>\n",
       "</g>\n",
       "<!-- 139874067593368&#45;&gt;139874067065432 -->\n",
       "<g class=\"edge\" id=\"edge4\">\n",
       "<title>139874067593368-&gt;139874067065432</title>\n",
       "<path d=\"M273,-415.3799C273,-407.1745 273,-397.7679 273,-388.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"276.5001,-388.784 273,-378.784 269.5001,-388.784 276.5001,-388.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139874067065824 -->\n",
       "<g class=\"node\" id=\"node6\">\n",
       "<title>139874067065824</title>\n",
       "<polygon fill=\"none\" points=\"0,-249.5 0,-295.5 546,-295.5 546,-249.5 0,-249.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"175\" y=\"-268.8\">global_max_pooling1d_4: GlobalMaxPooling1D</text>\n",
       "<polyline fill=\"none\" points=\"350,-249.5 350,-295.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"384\" y=\"-280.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"350,-272.5 418,-272.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"384\" y=\"-257.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"418,-249.5 418,-295.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"482\" y=\"-280.3\">(None, 350, 64)</text>\n",
       "<polyline fill=\"none\" points=\"418,-272.5 546,-272.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"482\" y=\"-257.3\">(None, 64)</text>\n",
       "</g>\n",
       "<!-- 139874067065432&#45;&gt;139874067065824 -->\n",
       "<g class=\"edge\" id=\"edge5\">\n",
       "<title>139874067065432-&gt;139874067065824</title>\n",
       "<path d=\"M273,-332.3799C273,-324.1745 273,-314.7679 273,-305.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"276.5001,-305.784 273,-295.784 269.5001,-305.784 276.5001,-305.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139874067065880 -->\n",
       "<g class=\"node\" id=\"node7\">\n",
       "<title>139874067065880</title>\n",
       "<polygon fill=\"none\" points=\"27,-166.5 27,-212.5 519,-212.5 519,-166.5 27,-166.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"193\" y=\"-185.8\">batch_normalization_9: BatchNormalization</text>\n",
       "<polyline fill=\"none\" points=\"359,-166.5 359,-212.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"393\" y=\"-197.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"359,-189.5 427,-189.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"393\" y=\"-174.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"427,-166.5 427,-212.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"473\" y=\"-197.3\">(None, 64)</text>\n",
       "<polyline fill=\"none\" points=\"427,-189.5 519,-189.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"473\" y=\"-174.3\">(None, 64)</text>\n",
       "</g>\n",
       "<!-- 139874067065824&#45;&gt;139874067065880 -->\n",
       "<g class=\"edge\" id=\"edge6\">\n",
       "<title>139874067065824-&gt;139874067065880</title>\n",
       "<path d=\"M273,-249.3799C273,-241.1745 273,-231.7679 273,-222.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"276.5001,-222.784 273,-212.784 269.5001,-222.784 276.5001,-222.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139874081632832 -->\n",
       "<g class=\"node\" id=\"node8\">\n",
       "<title>139874081632832</title>\n",
       "<polygon fill=\"none\" points=\"124.5,-83.5 124.5,-129.5 421.5,-129.5 421.5,-83.5 124.5,-83.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"193\" y=\"-102.8\">dense_17: Dense</text>\n",
       "<polyline fill=\"none\" points=\"261.5,-83.5 261.5,-129.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"295.5\" y=\"-114.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"261.5,-106.5 329.5,-106.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"295.5\" y=\"-91.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"329.5,-83.5 329.5,-129.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"375.5\" y=\"-114.3\">(None, 64)</text>\n",
       "<polyline fill=\"none\" points=\"329.5,-106.5 421.5,-106.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"375.5\" y=\"-91.3\">(None, 32)</text>\n",
       "</g>\n",
       "<!-- 139874067065880&#45;&gt;139874081632832 -->\n",
       "<g class=\"edge\" id=\"edge7\">\n",
       "<title>139874067065880-&gt;139874081632832</title>\n",
       "<path d=\"M273,-166.3799C273,-158.1745 273,-148.7679 273,-139.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"276.5001,-139.784 273,-129.784 269.5001,-139.784 276.5001,-139.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139874094442480 -->\n",
       "<g class=\"node\" id=\"node9\">\n",
       "<title>139874094442480</title>\n",
       "<polygon fill=\"none\" points=\"124.5,-.5 124.5,-46.5 421.5,-46.5 421.5,-.5 124.5,-.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"193\" y=\"-19.8\">dense_18: Dense</text>\n",
       "<polyline fill=\"none\" points=\"261.5,-.5 261.5,-46.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"295.5\" y=\"-31.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"261.5,-23.5 329.5,-23.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"295.5\" y=\"-8.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"329.5,-.5 329.5,-46.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"375.5\" y=\"-31.3\">(None, 32)</text>\n",
       "<polyline fill=\"none\" points=\"329.5,-23.5 421.5,-23.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"375.5\" y=\"-8.3\">(None, 1)</text>\n",
       "</g>\n",
       "<!-- 139874081632832&#45;&gt;139874094442480 -->\n",
       "<g class=\"edge\" id=\"edge8\">\n",
       "<title>139874081632832-&gt;139874094442480</title>\n",
       "<path d=\"M273,-83.3799C273,-75.1745 273,-65.7679 273,-56.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"276.5001,-56.784 273,-46.784 269.5001,-56.784 276.5001,-56.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 22500 samples, validate on 2500 samples\n",
      "Epoch 1/4\n",
      "22016/22500 [============================>.] - ETA: 0s - loss: 0.4677 - acc: 0.7769\n",
      "Epoch 00001: val_loss improved from inf to 0.29211, saving model to models/keras_model_weights.hdf5\n",
      "22500/22500 [==============================] - 47s 2ms/step - loss: 0.4642 - acc: 0.7791 - val_loss: 0.2921 - val_acc: 0.8828\n",
      "Epoch 2/4\n",
      "22016/22500 [============================>.] - ETA: 0s - loss: 0.1801 - acc: 0.9362\n",
      "Epoch 00002: val_loss did not improve\n",
      "22500/22500 [==============================] - 42s 2ms/step - loss: 0.1797 - acc: 0.9363 - val_loss: 0.3848 - val_acc: 0.8436\n",
      "Epoch 3/4\n",
      "22016/22500 [============================>.] - ETA: 0s - loss: 0.0683 - acc: 0.9836\n",
      "Epoch 00003: val_loss did not improve\n",
      "22500/22500 [==============================] - 42s 2ms/step - loss: 0.0686 - acc: 0.9834 - val_loss: 0.2938 - val_acc: 0.8912\n",
      "Epoch 4/4\n",
      "22016/22500 [============================>.] - ETA: 0s - loss: 0.0263 - acc: 0.9964\n",
      "Epoch 00004: val_loss did not improve\n",
      "22500/22500 [==============================] - 42s 2ms/step - loss: 0.0261 - acc: 0.9964 - val_loss: 0.4605 - val_acc: 0.8732\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f36f3c18dd8>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=BATCH_SIZE, epochs=EPOCHS, validation_data=[X_val, y_val], callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = load_model(filepath=FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_val_hat = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8828\n",
      "[[1022  206]\n",
      " [  87 1185]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.83      0.87      1228\n",
      "          1       0.85      0.93      0.89      1272\n",
      "\n",
      "avg / total       0.89      0.88      0.88      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_val, y_val_hat > 0.5))\n",
    "print(confusion_matrix(y_val, y_val_hat > 0.5))\n",
    "print(classification_report(y_val, y_val_hat > 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Useful tutorials:\n",
    "* http://konukoii.com/blog/2018/02/19/twitter-sentiment-analysis-using-combined-lstm-cnn-models/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Model - Use Pretrained Embeddings, PoS Parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prep Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_FEATURES = 65000\n",
    "MAX_LEN = 350"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_sentences_train = train['review'].fillna(\"UNKNOWN\").values.tolist()\n",
    "list_sentences_test = test['review'].fillna(\"UNKNOWN\").values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_sentences_train_parsed = [transform_doc(x, MAX_LEN=1000) for x in list_sentences_train]\n",
    "list_sentences_test_parsed = [transform_doc(x, MAX_LEN=1000) for x in list_sentences_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('data/list_sentences_train_parsed.pkl', 'wb') as f:\n",
    "    pickle.dump(list_sentences_train_parsed, f)\n",
    "    \n",
    "with open('data/list_sentences_test_parsed.pkl', 'wb') as f:\n",
    "    pickle.dump(list_sentences_test_parsed, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = text.Tokenizer(num_words=MAX_FEATURES, filters='!\"#$%&()*+,-/:;<=>?@[\\\\]^`{}~\\t\\n', lower=False)\n",
    "tokenizer.fit_on_texts(list_sentences_train_parsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_tokenized_train = tokenizer.texts_to_sequences(list_sentences_train_parsed)\n",
    "list_tokenized_test = tokenizer.texts_to_sequences(list_sentences_test_parsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = sequence.pad_sequences(list_tokenized_train, maxlen=MAX_LEN)\n",
    "X_test = sequence.pad_sequences(list_tokenized_test, maxlen=MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train['sentiment'].values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"With|ADP all_this_stuff|NOUN going|VERB down|PART at|ADP the_moment|NOUN with|ADP MJ|ENT i|PRON 've|VERB started|VERB listening|VERB to|ADP his_music|NOUN ,|PUNCT watching|VERB the_odd_documentary|NOUN here|ADV and|CCONJ there|ADV ,|PUNCT watched|VERB The_Wiz|PROPN and|CCONJ watched|VERB Moonwalker|ENT again|ADV .|PUNCT Maybe|ADV i|PRON just|ADV want|VERB to|PART get|VERB a_certain_insight|NOUN into|ADP this_guy|NOUN who|NOUN i|PRON thought|VERB was|VERB really|ADV cool|ADJ in|ADP the_eighties|DATE just|ADV to|PART maybe|ADV make|VERB up|PART my_mind|NOUN whether|ADP he|PRON is|VERB guilty|ADJ or|CCONJ innocent|ADJ .|PUNCT Moonwalker|ENT is|VERB part_biography|NOUN ,|PUNCT part_feature_film|NOUN which|ADJ i|PRON remember|VERB going|VERB to|PART see|VERB at|ADP the_cinema|NOUN when|ADV it|PRON was|VERB originally|ADV released|VERB .|PUNCT Some|DET of|ADP it|PRON has|VERB subtle_messages|NOUN about|ADP MJ's_feeling|NOUN towards|ADP the_press|NOUN and|CCONJ also|ADV the_obvious_message|NOUN of|ADP drugs|NOUN are|VERB bad_m'kay.<br|NOUN /><br|SYM />Visually|ADV impressive|ADJ but|CCONJ of|ADP course|NOUN this|DET is|VERB all|DET about|ADP Michael_Jackson|ENT so|ADP unless|ADP you|PRON remotely|ADV like|ADP MJ|ENT in|ADP anyway|ADV then|ADV you|PRON are|VERB going|VERB to|PART hate|VERB this|DET and|CCONJ find|VERB it|PRON boring|ADJ .|PUNCT Some|DET may|VERB call|VERB MJ|ENT an|DET egotist|NOUN for|ADP consenting|VERB to|ADP the_making|NOUN of|ADP this_movie|NOUN BUT|CCONJ MJ|ENT and|CCONJ most|ADJ of|ADP his_fans|NOUN would|VERB say|VERB that|ADP he|PRON made|VERB it|PRON for|ADP the_fans|NOUN which|ADJ if|ADP true|ADJ is|VERB really|ADV nice|ADJ of|ADP him.<br|CARDINAL /><br|PUNCT />The|SYM actual|ADJ feature|NOUN film|NOUN bit|NOUN when|ADV it|PRON finally|ADV starts|VERB is|VERB only|ADV on|ADP for|ADP 20_minutes|TIME or|CCONJ so|ADV excluding|VERB the_Smooth_Criminal_sequence|NOUN and|CCONJ Joe_Pesci|ENT is|VERB convincing|ADJ as|ADP a_psychopathic_all_powerful_drug_lord|NOUN .|PUNCT Why|ADV he|PRON wants|VERB MJ|ENT dead|ADJ so|ADV bad|ADJ is|VERB beyond|ADP me|PRON .|PUNCT Because|ADP MJ|ENT overheard|VERB his_plans|NOUN ?|PUNCT Nah|ENT ,|PUNCT Joe_Pesci's_character|NOUN ranted|VERB that|ADP he|PRON wanted|VERB people|NOUN to|PART know|VERB it|PRON is|VERB he|PRON who|NOUN is|VERB supplying|VERB drugs|NOUN etc|X so|ADV i|PRON dunno|VERB ,|PUNCT maybe|ADV he|PRON just|ADV hates|VERB MJ's_music.<br|ENT /><br|PUNCT />Lots|NOUN of|ADP cool_things|NOUN in|ADP this|DET like|ADP MJ|ENT turning|VERB into|ADP a_car|NOUN and|CCONJ a_robot|NOUN and|CCONJ the_whole_Speed_Demon_sequence|NOUN .|PUNCT Also|ADV ,|PUNCT the_director|NOUN must|VERB have|VERB had|VERB the_patience|NOUN of|ADP a_saint|NOUN when|ADV it|PRON came|VERB to|ADP filming|VERB the_kiddy|NOUN Bad_sequence|NOUN as|ADP usually|ADV directors|NOUN hate|VERB working|VERB with|ADP one_kid|NOUN let|VERB alone|ADV a_whole_bunch|NOUN of|ADP them|PRON performing|VERB a_complex_dance|NOUN scene.<br|ENT /><br|SYM />Bottom|NOUN line|NOUN ,|PUNCT this_movie|NOUN is|VERB for|ADP people|NOUN who|NOUN like|VERB MJ|ENT on|ADP one_level|NOUN or|CCONJ another|DET (|PUNCT which|ADJ i|PRON think|VERB is|VERB most_people|NOUN )|PUNCT .|PUNCT If|ADP not|ADV ,|PUNCT then|ADV stay|VERB away|ADV .|PUNCT It|PRON does|VERB try|VERB and|CCONJ give|VERB off|PART a_wholesome_message|NOUN and|CCONJ ironically_MJ's_bestest_buddy|NOUN in|ADP this_movie|NOUN is|VERB a_girl|NOUN !|PUNCT Michael_Jackson|ENT is|VERB truly|ADV one|CARDINAL of|ADP the_most_talented_people|NOUN ever|ADV to|PART grace|VERB this_planet|NOUN but|CCONJ is|VERB he|PRON guilty|ADJ ?|PUNCT Well|INTJ ,|PUNCT with|ADP all_the_attention|NOUN i|PRON 've|VERB gave|VERB this_subject|NOUN ....|PUNCT hmmm|INTJ well|INTJ i|PRON do|VERB n't|ADV know|VERB because|ADP people|NOUN can|VERB be|VERB different|ADJ behind|ADP closed_doors|NOUN ,|PUNCT i|PRON know|VERB this|DET for|ADP a_fact|NOUN .|PUNCT He|PRON is|VERB either_an_extremely_nice_but_stupid_guy|NOUN or|CCONJ one|CARDINAL of|ADP the_most_sickest_liars|NOUN .|PUNCT I|PRON hope|VERB he|PRON is|VERB not|ADV the|DET latter|ADJ .|PUNCT\""
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_sentences_train_parsed[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[427,\n",
       " 137,\n",
       " 214,\n",
       " 33,\n",
       " 1728,\n",
       " 13,\n",
       " 10013,\n",
       " 117,\n",
       " 123,\n",
       " 441,\n",
       " 1956,\n",
       " 12,\n",
       " 9053,\n",
       " 1,\n",
       " 130,\n",
       " 122,\n",
       " 3,\n",
       " 47,\n",
       " 1,\n",
       " 220,\n",
       " 3,\n",
       " 220,\n",
       " 14945,\n",
       " 151,\n",
       " 2,\n",
       " 550,\n",
       " 117,\n",
       " 44,\n",
       " 147,\n",
       " 6,\n",
       " 73,\n",
       " 72,\n",
       " 1979,\n",
       " 29,\n",
       " 117,\n",
       " 174,\n",
       " 10,\n",
       " 61,\n",
       " 829,\n",
       " 7,\n",
       " 7258,\n",
       " 44,\n",
       " 6,\n",
       " 353,\n",
       " 87,\n",
       " 59,\n",
       " 1491,\n",
       " 562,\n",
       " 26,\n",
       " 5,\n",
       " 3109,\n",
       " 38,\n",
       " 2622,\n",
       " 2,\n",
       " 14945,\n",
       " 5,\n",
       " 1,\n",
       " 52,\n",
       " 117,\n",
       " 302,\n",
       " 137,\n",
       " 6,\n",
       " 58,\n",
       " 33,\n",
       " 1580,\n",
       " 50,\n",
       " 9,\n",
       " 10,\n",
       " 1306,\n",
       " 460,\n",
       " 2,\n",
       " 699,\n",
       " 4,\n",
       " 9,\n",
       " 36,\n",
       " 53886,\n",
       " 42,\n",
       " 660,\n",
       " 10795,\n",
       " 3,\n",
       " 88,\n",
       " 4,\n",
       " 1441,\n",
       " 20,\n",
       " 39,\n",
       " 83,\n",
       " 6477,\n",
       " 1249,\n",
       " 16,\n",
       " 4,\n",
       " 305,\n",
       " 35,\n",
       " 5,\n",
       " 78,\n",
       " 42,\n",
       " 5265,\n",
       " 279,\n",
       " 729,\n",
       " 19,\n",
       " 1810,\n",
       " 41,\n",
       " 10013,\n",
       " 7,\n",
       " 783,\n",
       " 96,\n",
       " 19,\n",
       " 20,\n",
       " 137,\n",
       " 6,\n",
       " 610,\n",
       " 35,\n",
       " 3,\n",
       " 134,\n",
       " 9,\n",
       " 418,\n",
       " 2,\n",
       " 699,\n",
       " 164,\n",
       " 579,\n",
       " 10013,\n",
       " 339,\n",
       " 14,\n",
       " 36321,\n",
       " 12,\n",
       " 3538,\n",
       " 4,\n",
       " 48,\n",
       " 3169,\n",
       " 10013,\n",
       " 3,\n",
       " 241,\n",
       " 4,\n",
       " 11248,\n",
       " 45,\n",
       " 113,\n",
       " 18,\n",
       " 26,\n",
       " 85,\n",
       " 9,\n",
       " 14,\n",
       " 4242,\n",
       " 52,\n",
       " 56,\n",
       " 468,\n",
       " 5,\n",
       " 61,\n",
       " 628,\n",
       " 4,\n",
       " 1528,\n",
       " 455,\n",
       " 11,\n",
       " 390,\n",
       " 8037,\n",
       " 7622,\n",
       " 199,\n",
       " 257,\n",
       " 50,\n",
       " 9,\n",
       " 377,\n",
       " 391,\n",
       " 5,\n",
       " 106,\n",
       " 22,\n",
       " 14,\n",
       " 7814,\n",
       " 38,\n",
       " 46,\n",
       " 18037,\n",
       " 3,\n",
       " 15867,\n",
       " 5,\n",
       " 1046,\n",
       " 15,\n",
       " 2,\n",
       " 402,\n",
       " 26,\n",
       " 357,\n",
       " 10013,\n",
       " 598,\n",
       " 46,\n",
       " 127,\n",
       " 5,\n",
       " 530,\n",
       " 64,\n",
       " 2,\n",
       " 901,\n",
       " 10013,\n",
       " 43237,\n",
       " 27862,\n",
       " 1,\n",
       " 20960,\n",
       " 1,\n",
       " 43238,\n",
       " 18,\n",
       " 26,\n",
       " 347,\n",
       " 144,\n",
       " 6,\n",
       " 103,\n",
       " 9,\n",
       " 5,\n",
       " 26,\n",
       " 29,\n",
       " 5,\n",
       " 20961,\n",
       " 1441,\n",
       " 406,\n",
       " 46,\n",
       " 117,\n",
       " 12792,\n",
       " 1,\n",
       " 353,\n",
       " 26,\n",
       " 44,\n",
       " 2880,\n",
       " 32,\n",
       " 11,\n",
       " 2859,\n",
       " 4,\n",
       " 7,\n",
       " 35,\n",
       " 41,\n",
       " 10013,\n",
       " 1156,\n",
       " 72,\n",
       " 2178,\n",
       " 3,\n",
       " 10014,\n",
       " 3,\n",
       " 2,\n",
       " 389,\n",
       " 1,\n",
       " 381,\n",
       " 169,\n",
       " 23,\n",
       " 55,\n",
       " 15868,\n",
       " 4,\n",
       " 16903,\n",
       " 50,\n",
       " 9,\n",
       " 285,\n",
       " 12,\n",
       " 2238,\n",
       " 15,\n",
       " 501,\n",
       " 2169,\n",
       " 610,\n",
       " 661,\n",
       " 13,\n",
       " 43239,\n",
       " 270,\n",
       " 581,\n",
       " 10386,\n",
       " 4,\n",
       " 86,\n",
       " 2729,\n",
       " 6766,\n",
       " 32,\n",
       " 83,\n",
       " 10387,\n",
       " 1562,\n",
       " 1,\n",
       " 48,\n",
       " 5,\n",
       " 14,\n",
       " 144,\n",
       " 29,\n",
       " 153,\n",
       " 10013,\n",
       " 22,\n",
       " 18038,\n",
       " 38,\n",
       " 453,\n",
       " 1,\n",
       " 52,\n",
       " 117,\n",
       " 89,\n",
       " 5,\n",
       " 1592,\n",
       " 1,\n",
       " 2,\n",
       " 128,\n",
       " 24,\n",
       " 1,\n",
       " 96,\n",
       " 592,\n",
       " 211,\n",
       " 2,\n",
       " 37,\n",
       " 62,\n",
       " 294,\n",
       " 3,\n",
       " 159,\n",
       " 135,\n",
       " 3,\n",
       " 7,\n",
       " 48,\n",
       " 5,\n",
       " 1108,\n",
       " 1,\n",
       " 5265,\n",
       " 5,\n",
       " 375,\n",
       " 107,\n",
       " 4,\n",
       " 110,\n",
       " 6,\n",
       " 10388,\n",
       " 8038,\n",
       " 16,\n",
       " 5,\n",
       " 26,\n",
       " 3109,\n",
       " 1,\n",
       " 362,\n",
       " 1,\n",
       " 13,\n",
       " 36322,\n",
       " 117,\n",
       " 123,\n",
       " 370,\n",
       " 10015,\n",
       " 383,\n",
       " 16904,\n",
       " 481,\n",
       " 117,\n",
       " 40,\n",
       " 17,\n",
       " 103,\n",
       " 80,\n",
       " 144,\n",
       " 49,\n",
       " 25,\n",
       " 498,\n",
       " 435,\n",
       " 36323,\n",
       " 1,\n",
       " 117,\n",
       " 103,\n",
       " 35,\n",
       " 14,\n",
       " 9054,\n",
       " 2,\n",
       " 114,\n",
       " 5,\n",
       " 38,\n",
       " 107,\n",
       " 4,\n",
       " 2,\n",
       " 8,\n",
       " 464,\n",
       " 26,\n",
       " 5,\n",
       " 24,\n",
       " 34,\n",
       " 1563,\n",
       " 2]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_tokenized_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_word_dict = {v:k for k, v in tokenizer.word_index.items()}\n",
    "word_index_dict = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With|ADP\n",
      "going|VERB\n",
      "down|PART\n",
      "at|ADP\n",
      "the_moment|NOUN\n",
      "with|ADP\n",
      "MJ|ENT\n",
      "i|PRON\n",
      "'ve|VERB\n",
      "started|VERB\n",
      "listening|VERB\n",
      "to|ADP\n",
      "his_music|NOUN\n",
      "|PUNCT\n",
      "watching|VERB\n",
      "here|ADV\n",
      "and|CCONJ\n",
      "there|ADV\n",
      "|PUNCT\n",
      "watched|VERB\n",
      "and|CCONJ\n",
      "watched|VERB\n",
      "Moonwalker|ENT\n",
      "again|ADV\n",
      ".|PUNCT\n",
      "Maybe|ADV\n",
      "i|PRON\n",
      "just|ADV\n",
      "want|VERB\n",
      "to|PART\n",
      "get|VERB\n",
      "into|ADP\n",
      "this_guy|NOUN\n",
      "who|NOUN\n",
      "i|PRON\n",
      "thought|VERB\n",
      "was|VERB\n",
      "really|ADV\n",
      "cool|ADJ\n",
      "in|ADP\n",
      "the_eighties|DATE\n",
      "just|ADV\n",
      "to|PART\n",
      "maybe|ADV\n",
      "make|VERB\n",
      "up|PART\n",
      "my_mind|NOUN\n",
      "whether|ADP\n",
      "he|PRON\n",
      "is|VERB\n",
      "guilty|ADJ\n",
      "or|CCONJ\n",
      "innocent|ADJ\n",
      ".|PUNCT\n",
      "Moonwalker|ENT\n",
      "is|VERB\n",
      "|PUNCT\n",
      "which|ADJ\n",
      "i|PRON\n",
      "remember|VERB\n",
      "going|VERB\n",
      "to|PART\n",
      "see|VERB\n",
      "at|ADP\n",
      "the_cinema|NOUN\n",
      "when|ADV\n",
      "it|PRON\n",
      "was|VERB\n",
      "originally|ADV\n",
      "released|VERB\n",
      ".|PUNCT\n",
      "Some|DET\n",
      "of|ADP\n",
      "it|PRON\n",
      "has|VERB\n",
      "subtle_messages|NOUN\n",
      "about|ADP\n",
      "towards|ADP\n",
      "the_press|NOUN\n",
      "and|CCONJ\n",
      "also|ADV\n",
      "of|ADP\n",
      "drugs|NOUN\n",
      "are|VERB\n",
      "br|NOUN\n",
      "br|SYM\n",
      "Visually|ADV\n",
      "impressive|ADJ\n",
      "but|CCONJ\n",
      "of|ADP\n",
      "course|NOUN\n",
      "this|DET\n",
      "is|VERB\n",
      "all|DET\n",
      "about|ADP\n",
      "Michael_Jackson|ENT\n",
      "so|ADP\n",
      "unless|ADP\n",
      "you|PRON\n",
      "remotely|ADV\n",
      "like|ADP\n",
      "MJ|ENT\n",
      "in|ADP\n",
      "anyway|ADV\n",
      "then|ADV\n",
      "you|PRON\n",
      "are|VERB\n",
      "going|VERB\n",
      "to|PART\n",
      "hate|VERB\n",
      "this|DET\n",
      "and|CCONJ\n",
      "find|VERB\n",
      "it|PRON\n",
      "boring|ADJ\n",
      ".|PUNCT\n",
      "Some|DET\n",
      "may|VERB\n",
      "call|VERB\n",
      "MJ|ENT\n",
      "an|DET\n",
      "for|ADP\n",
      "consenting|VERB\n",
      "to|ADP\n",
      "the_making|NOUN\n",
      "of|ADP\n",
      "this_movie|NOUN\n",
      "BUT|CCONJ\n",
      "MJ|ENT\n",
      "and|CCONJ\n",
      "most|ADJ\n",
      "of|ADP\n",
      "his_fans|NOUN\n",
      "would|VERB\n",
      "say|VERB\n",
      "that|ADP\n",
      "he|PRON\n",
      "made|VERB\n",
      "it|PRON\n",
      "for|ADP\n",
      "the_fans|NOUN\n",
      "which|ADJ\n",
      "if|ADP\n",
      "true|ADJ\n",
      "is|VERB\n",
      "really|ADV\n",
      "nice|ADJ\n",
      "of|ADP\n",
      "him.\n",
      "br|CARDINAL\n",
      "br|PUNCT\n",
      "The|SYM\n",
      "actual|ADJ\n",
      "feature|NOUN\n",
      "film|NOUN\n",
      "bit|NOUN\n",
      "when|ADV\n",
      "it|PRON\n",
      "finally|ADV\n",
      "starts|VERB\n",
      "is|VERB\n",
      "only|ADV\n",
      "on|ADP\n",
      "for|ADP\n",
      "20_minutes|TIME\n",
      "or|CCONJ\n",
      "so|ADV\n",
      "excluding|VERB\n",
      "and|CCONJ\n",
      "Joe_Pesci|ENT\n",
      "is|VERB\n",
      "convincing|ADJ\n",
      "as|ADP\n",
      ".|PUNCT\n",
      "Why|ADV\n",
      "he|PRON\n",
      "wants|VERB\n",
      "MJ|ENT\n",
      "dead|ADJ\n",
      "so|ADV\n",
      "bad|ADJ\n",
      "is|VERB\n",
      "beyond|ADP\n",
      "me|PRON\n",
      ".|PUNCT\n",
      "Because|ADP\n",
      "MJ|ENT\n",
      "overheard|VERB\n",
      "his_plans|NOUN\n",
      "|PUNCT\n",
      "Nah|ENT\n",
      "|PUNCT\n",
      "ranted|VERB\n",
      "that|ADP\n",
      "he|PRON\n",
      "wanted|VERB\n",
      "people|NOUN\n",
      "to|PART\n",
      "know|VERB\n",
      "it|PRON\n",
      "is|VERB\n",
      "he|PRON\n",
      "who|NOUN\n",
      "is|VERB\n",
      "supplying|VERB\n",
      "drugs|NOUN\n",
      "etc|X\n",
      "so|ADV\n",
      "i|PRON\n",
      "dunno|VERB\n",
      "|PUNCT\n",
      "maybe|ADV\n",
      "he|PRON\n",
      "just|ADV\n",
      "hates|VERB\n",
      "br|ENT\n",
      "br|PUNCT\n",
      "Lots|NOUN\n",
      "of|ADP\n",
      "in|ADP\n",
      "this|DET\n",
      "like|ADP\n",
      "MJ|ENT\n",
      "turning|VERB\n",
      "into|ADP\n",
      "a_car|NOUN\n",
      "and|CCONJ\n",
      "a_robot|NOUN\n",
      "and|CCONJ\n",
      ".|PUNCT\n",
      "Also|ADV\n",
      "|PUNCT\n",
      "the_director|NOUN\n",
      "must|VERB\n",
      "have|VERB\n",
      "had|VERB\n",
      "the_patience|NOUN\n",
      "of|ADP\n",
      "a_saint|NOUN\n",
      "when|ADV\n",
      "it|PRON\n",
      "came|VERB\n",
      "to|ADP\n",
      "filming|VERB\n",
      "as|ADP\n",
      "usually|ADV\n",
      "directors|NOUN\n",
      "hate|VERB\n",
      "working|VERB\n",
      "with|ADP\n",
      "one_kid|NOUN\n",
      "let|VERB\n",
      "alone|ADV\n",
      "a_whole_bunch|NOUN\n",
      "of|ADP\n",
      "them|PRON\n",
      "performing|VERB\n",
      "scene.\n",
      "br|ENT\n",
      "br|SYM\n",
      "Bottom|NOUN\n",
      "line|NOUN\n",
      "|PUNCT\n",
      "this_movie|NOUN\n",
      "is|VERB\n",
      "for|ADP\n",
      "people|NOUN\n",
      "who|NOUN\n",
      "like|VERB\n",
      "MJ|ENT\n",
      "on|ADP\n",
      "one_level|NOUN\n",
      "or|CCONJ\n",
      "another|DET\n",
      "|PUNCT\n",
      "which|ADJ\n",
      "i|PRON\n",
      "think|VERB\n",
      "is|VERB\n",
      "most_people|NOUN\n",
      "|PUNCT\n",
      ".|PUNCT\n",
      "If|ADP\n",
      "not|ADV\n",
      "|PUNCT\n",
      "then|ADV\n",
      "stay|VERB\n",
      "away|ADV\n",
      ".|PUNCT\n",
      "It|PRON\n",
      "does|VERB\n",
      "try|VERB\n",
      "and|CCONJ\n",
      "give|VERB\n",
      "off|PART\n",
      "and|CCONJ\n",
      "in|ADP\n",
      "this_movie|NOUN\n",
      "is|VERB\n",
      "a_girl|NOUN\n",
      "|PUNCT\n",
      "Michael_Jackson|ENT\n",
      "is|VERB\n",
      "truly|ADV\n",
      "one|CARDINAL\n",
      "of|ADP\n",
      "ever|ADV\n",
      "to|PART\n",
      "grace|VERB\n",
      "this_planet|NOUN\n",
      "but|CCONJ\n",
      "is|VERB\n",
      "he|PRON\n",
      "guilty|ADJ\n",
      "|PUNCT\n",
      "Well|INTJ\n",
      "|PUNCT\n",
      "with|ADP\n",
      "all_the_attention|NOUN\n",
      "i|PRON\n",
      "'ve|VERB\n",
      "gave|VERB\n",
      "this_subject|NOUN\n",
      "....|PUNCT\n",
      "hmmm|INTJ\n",
      "well|INTJ\n",
      "i|PRON\n",
      "do|VERB\n",
      "n't|ADV\n",
      "know|VERB\n",
      "because|ADP\n",
      "people|NOUN\n",
      "can|VERB\n",
      "be|VERB\n",
      "different|ADJ\n",
      "behind|ADP\n",
      "closed_doors|NOUN\n",
      "|PUNCT\n",
      "i|PRON\n",
      "know|VERB\n",
      "this|DET\n",
      "for|ADP\n",
      "a_fact|NOUN\n",
      ".|PUNCT\n",
      "He|PRON\n",
      "is|VERB\n",
      "or|CCONJ\n",
      "one|CARDINAL\n",
      "of|ADP\n",
      ".|PUNCT\n",
      "I|PRON\n",
      "hope|VERB\n",
      "he|PRON\n",
      "is|VERB\n",
      "not|ADV\n",
      "the|DET\n",
      "latter|ADJ\n",
      ".|PUNCT\n"
     ]
    }
   ],
   "source": [
    "for w in list_tokenized_train[0]:\n",
    "    print(index_word_dict[w])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Embedding Matrix\n",
    "(or load one if you have it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec.load('models/w2v_model_128')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of the gensim word2vec vocab is: 67600\n",
      "The size of the keras token vocab is: 515041\n",
      "The tokenizer vocab is limited to: 65000\n",
      "Total amount of words not found in gensim word2vec model: 9831\n",
      "Embedding matrix shape: (65001, 128)\n"
     ]
    }
   ],
   "source": [
    "EMBED_SIZE = w2v_model.vector_size\n",
    "print('The size of the gensim word2vec vocab is: {}'.format(len(w2v_model.wv.vocab.items())))\n",
    "\n",
    "unknown_word_count = 0\n",
    "def choose_embedded_vector(word, unknown_word_count, verbose=False):\n",
    "    if word in w2v_model.wv.vocab:\n",
    "        return w2v_model.wv.word_vec(word), unknown_word_count\n",
    "    else:\n",
    "        if verbose:\n",
    "            print('Unknown word: {}'.format(word))\n",
    "        return np.random.rand(EMBED_SIZE), (unknown_word_count+1)\n",
    "\n",
    "index_word_dict = {v:k for k, v in tokenizer.word_index.items()}\n",
    "word_index_dict = tokenizer.word_index\n",
    "num_words = tokenizer.num_words + 1 \n",
    "print('The size of the keras token vocab is: {}'.format(len(index_word_dict)))\n",
    "print('The tokenizer vocab is limited to: {}'.format(tokenizer.num_words))\n",
    "\n",
    "\n",
    "embedding_weights = np.zeros((num_words, EMBED_SIZE))\n",
    "for word, index in word_index_dict.items():\n",
    "    if index < num_words:\n",
    "        embedding_weights[index,:], unknown_word_count = choose_embedded_vector(word, unknown_word_count)\n",
    "\n",
    "print('Total amount of words not found in gensim word2vec model: {}'.format(unknown_word_count))\n",
    "print('Embedding matrix shape: {}'.format(embedding_weights.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    input_sequence = Input(shape=(MAX_LEN, ))\n",
    "    x = Embedding(input_dim=num_words, output_dim=EMBED_SIZE, input_length=MAX_LEN, mask_zero=False, weights=[embedding_weights], trainable=True)(input_sequence)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Conv1D(filters=64, kernel_size=2, padding='same')(x)\n",
    "    x = Bidirectional(LSTM(32,\n",
    "                           return_sequences=True,\n",
    "                           kernel_regularizer=l2(0.0001)))(x)\n",
    "    x = AttentionWithContext()(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(32, activation=\"elu\", kernel_regularizer=l2(0.0001))(x)\n",
    "    prediction = Dense(N_CLASSES, activation=\"sigmoid\")(x)\n",
    "    \n",
    "    model = Model(inputs=input_sequence, outputs=prediction)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "\n",
    "BATCH_SIZE = 512\n",
    "EPOCHS = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FILE_PATH = \"models/keras_model_weights.hdf5\"\n",
    "checkpoint = ModelCheckpoint(FILE_PATH, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=5)\n",
    "callbacks_list = [checkpoint, early]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_12 (InputLayer)        (None, 350)               0         \n",
      "_________________________________________________________________\n",
      "embedding_12 (Embedding)     (None, 350, 128)          8320128   \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 350, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 350, 64)           16448     \n",
      "_________________________________________________________________\n",
      "bidirectional_12 (Bidirectio (None, 350, 64)           24832     \n",
      "_________________________________________________________________\n",
      "attention_with_context_1 (At (None, 64)                4224      \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 8,368,001\n",
      "Trainable params: 8,367,873\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 22500 samples, validate on 2500 samples\n",
      "Epoch 1/16\n",
      "22016/22500 [============================>.] - ETA: 0s - loss: 0.5839 - acc: 0.6969\n",
      "Epoch 00001: val_loss improved from inf to 0.47400, saving model to models/keras_model_weights.hdf5\n",
      "22500/22500 [==============================] - 42s 2ms/step - loss: 0.5825 - acc: 0.6980 - val_loss: 0.4740 - val_acc: 0.7844\n",
      "Epoch 2/16\n",
      "22016/22500 [============================>.] - ETA: 0s - loss: 0.4274 - acc: 0.8093\n",
      "Epoch 00002: val_loss improved from 0.47400 to 0.38924, saving model to models/keras_model_weights.hdf5\n",
      "22500/22500 [==============================] - 38s 2ms/step - loss: 0.4263 - acc: 0.8095 - val_loss: 0.3892 - val_acc: 0.8276\n",
      "Epoch 3/16\n",
      "22016/22500 [============================>.] - ETA: 0s - loss: 0.3479 - acc: 0.8547\n",
      "Epoch 00003: val_loss improved from 0.38924 to 0.35733, saving model to models/keras_model_weights.hdf5\n",
      "22500/22500 [==============================] - 39s 2ms/step - loss: 0.3475 - acc: 0.8550 - val_loss: 0.3573 - val_acc: 0.8496\n",
      "Epoch 4/16\n",
      "22016/22500 [============================>.] - ETA: 0s - loss: 0.2963 - acc: 0.8795\n",
      "Epoch 00004: val_loss improved from 0.35733 to 0.35707, saving model to models/keras_model_weights.hdf5\n",
      "22500/22500 [==============================] - 38s 2ms/step - loss: 0.2966 - acc: 0.8795 - val_loss: 0.3571 - val_acc: 0.8544\n",
      "Epoch 5/16\n",
      "22016/22500 [============================>.] - ETA: 0s - loss: 0.2528 - acc: 0.9016\n",
      "Epoch 00005: val_loss improved from 0.35707 to 0.33521, saving model to models/keras_model_weights.hdf5\n",
      "22500/22500 [==============================] - 37s 2ms/step - loss: 0.2518 - acc: 0.9019 - val_loss: 0.3352 - val_acc: 0.8692\n",
      "Epoch 6/16\n",
      "22016/22500 [============================>.] - ETA: 0s - loss: 0.2122 - acc: 0.9211\n",
      "Epoch 00006: val_loss did not improve\n",
      "22500/22500 [==============================] - 37s 2ms/step - loss: 0.2123 - acc: 0.9212 - val_loss: 0.3788 - val_acc: 0.8608\n",
      "Epoch 7/16\n",
      "22016/22500 [============================>.] - ETA: 0s - loss: 0.1738 - acc: 0.9371\n",
      "Epoch 00007: val_loss did not improve\n",
      "22500/22500 [==============================] - 37s 2ms/step - loss: 0.1742 - acc: 0.9370 - val_loss: 0.3414 - val_acc: 0.8768\n",
      "Epoch 8/16\n",
      "22016/22500 [============================>.] - ETA: 0s - loss: 0.1431 - acc: 0.9494\n",
      "Epoch 00008: val_loss improved from 0.33521 to 0.32490, saving model to models/keras_model_weights.hdf5\n",
      "22500/22500 [==============================] - 36s 2ms/step - loss: 0.1432 - acc: 0.9496 - val_loss: 0.3249 - val_acc: 0.8860\n",
      "Epoch 9/16\n",
      "22016/22500 [============================>.] - ETA: 0s - loss: 0.1178 - acc: 0.9613\n",
      "Epoch 00009: val_loss did not improve\n",
      "22500/22500 [==============================] - 36s 2ms/step - loss: 0.1179 - acc: 0.9614 - val_loss: 0.3627 - val_acc: 0.8820\n",
      "Epoch 10/16\n",
      "22016/22500 [============================>.] - ETA: 0s - loss: 0.0965 - acc: 0.9686\n",
      "Epoch 00010: val_loss did not improve\n",
      "22500/22500 [==============================] - 36s 2ms/step - loss: 0.0962 - acc: 0.9688 - val_loss: 0.3969 - val_acc: 0.8848\n",
      "Epoch 11/16\n",
      "22016/22500 [============================>.] - ETA: 0s - loss: 0.0795 - acc: 0.9748\n",
      "Epoch 00011: val_loss did not improve\n",
      "22500/22500 [==============================] - 36s 2ms/step - loss: 0.0799 - acc: 0.9745 - val_loss: 0.4363 - val_acc: 0.8744\n",
      "Epoch 12/16\n",
      "22016/22500 [============================>.] - ETA: 0s - loss: 0.0641 - acc: 0.9820\n",
      "Epoch 00012: val_loss did not improve\n",
      "22500/22500 [==============================] - 36s 2ms/step - loss: 0.0646 - acc: 0.9816 - val_loss: 0.4696 - val_acc: 0.8712\n",
      "Epoch 13/16\n",
      "22016/22500 [============================>.] - ETA: 0s - loss: 0.0575 - acc: 0.9838\n",
      "Epoch 00013: val_loss did not improve\n",
      "22500/22500 [==============================] - 36s 2ms/step - loss: 0.0576 - acc: 0.9838 - val_loss: 0.4737 - val_acc: 0.8784\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f36b23cc320>"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=BATCH_SIZE, epochs=EPOCHS, validation_data=[X_val, y_val], callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f36a6c15208>"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAAHVCAYAAAADyWaQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMigki4iIiIhk+P+ubGfC85s9MgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f36a89a34e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(model.history.history).plot(figsize=(12,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = load_model(filepath=FILE_PATH, custom_objects={'AttentionWithContext':AttentionWithContext})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_hat = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.886\n",
      "[[1069  159]\n",
      " [ 126 1146]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.87      0.88      1228\n",
      "          1       0.88      0.90      0.89      1272\n",
      "\n",
      "avg / total       0.89      0.89      0.89      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_val, y_hat > 0.5))\n",
    "print(confusion_matrix(y_val, y_hat > 0.5))\n",
    "print(classification_report(y_val, y_hat > 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lot of the spacy code was pulled from examples: https://github.com/explosion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "LABELS = {\n",
    "    'ENT': 'ENT',\n",
    "    'PERSON': 'ENT',\n",
    "    'NORP': 'ENT',\n",
    "    'FAC': 'ENT',\n",
    "    'ORG': 'ENT',\n",
    "    'GPE': 'ENT',\n",
    "    'LOC': 'ENT',\n",
    "    'LAW': 'ENT',\n",
    "    'PRODUCT': 'ENT',\n",
    "    'EVENT': 'ENT',\n",
    "    'WORK_OF_ART': 'ENT',\n",
    "    'LANGUAGE': 'ENT',\n",
    "    'DATE': 'DATE',\n",
    "    'TIME': 'TIME',\n",
    "    'PERCENT': 'PERCENT',\n",
    "    'MONEY': 'MONEY',\n",
    "    'QUANTITY': 'QUANTITY',\n",
    "    'ORDINAL': 'ORDINAL',\n",
    "    'CARDINAL': 'CARDINAL'\n",
    "}\n",
    "\n",
    "\n",
    "pre_format_re = re.compile(r'^[\\`\\*\\~]')\n",
    "post_format_re = re.compile(r'[\\`\\*\\~]$')\n",
    "url_re = re.compile(r'\\[([^]]+)\\]\\(%%URL\\)')\n",
    "link_re = re.compile(r'\\[([^]]+)\\]\\(https?://[^\\)]+\\)')\n",
    "\n",
    "\n",
    "def strip_meta(text):\n",
    "    if type(text) == str:\n",
    "        text = link_re.sub(r'\\1', text)\n",
    "        text = text.replace('&gt;', '>').replace('&lt;', '<')\n",
    "        text = pre_format_re.sub('', text)\n",
    "        text = post_format_re.sub('', text)\n",
    "        return text\n",
    "    else:\n",
    "        return ''\n",
    "    \n",
    "\n",
    "def represent_word(word):\n",
    "    if word.like_url:\n",
    "        return '%%URL|X'\n",
    "    text = re.sub(r'\\s', '_', word.text)\n",
    "    tag = LABELS.get(word.ent_type_, word.pos_)\n",
    "    if not tag:\n",
    "        tag = '?'\n",
    "    return text + '|' + tag\n",
    "\n",
    "\n",
    "def merge_clean_sentence(nlp, text, collapse_punctuation=True, collapse_phrases=True):\n",
    "    doc = nlp(text)\n",
    "    if collapse_punctuation:\n",
    "        spans = []\n",
    "        for word in doc[:-1]:\n",
    "            if word.is_punct:\n",
    "                continue\n",
    "            if not word.nbor(1).is_punct:\n",
    "                continue\n",
    "            start = word.i\n",
    "            end = word.i + 1\n",
    "            while end < len(doc) and doc[end].is_punct:\n",
    "                end += 1\n",
    "            span = doc[start : end]\n",
    "            spans.append(\n",
    "                (span.start_char, span.end_char,\n",
    "                 {'tag': word.tag_, 'lemma': word.lemma_, 'ent_type': word.ent_type_})\n",
    "            )\n",
    "        for start, end, attrs in spans:\n",
    "            doc.merge(start, end, **attrs)\n",
    "\n",
    "    if collapse_phrases:\n",
    "        for np in list(doc.noun_chunks):\n",
    "            np.merge(tag=np.root.tag_, lemma=np.root.lemma_, ent_type=np.root.ent_type_)\n",
    "    \n",
    "    return doc\n",
    "\n",
    "\n",
    "def transform_doc(text, MAX_LEN):\n",
    "    d = merge_clean_sentence(nlp, text, collapse_punctuation=False, collapse_phrases=True)\n",
    "    strings = []\n",
    "    for sent in d.sents:\n",
    "        if sent.text.strip():\n",
    "            for w in sent:\n",
    "                if not w.is_space:\n",
    "                    strings.append(represent_word(w))\n",
    "    if strings:\n",
    "        return ' '.join(strings[0:MAX_LEN])\n",
    "    else:\n",
    "        return ' '.join(['' for x in range(MAX_LEN)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attention adapted from: https://gist.github.com/cbaziotis/6428df359af27d58078ca5ed9792bd6d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dot_product(x, kernel):\n",
    "    \"\"\"\n",
    "    Wrapper for dot product operation, in order to be compatible with both\n",
    "    Theano and Tensorflow\n",
    "    Args:\n",
    "        x (): input\n",
    "        kernel (): weights\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    if K.backend() == 'tensorflow':\n",
    "        return K.squeeze(K.dot(x, K.expand_dims(kernel)), axis=-1)\n",
    "    else:\n",
    "        return K.dot(x, kernel)\n",
    "    \n",
    "\n",
    "class AttentionWithContext(Layer):\n",
    "    \"\"\"\n",
    "    Attention operation, with a context/query vector, for temporal data.\n",
    "    Supports Masking.\n",
    "    Follows the work of Yang et al. [https://www.cs.cmu.edu/~diyiy/docs/naacl16.pdf]\n",
    "    \"Hierarchical Attention Networks for Document Classification\"\n",
    "    by using a context vector to assist the attention\n",
    "    # Input shape\n",
    "        3D tensor with shape: `(samples, steps, features)`.\n",
    "    # Output shape\n",
    "        2D tensor with shape: `(samples, features)`.\n",
    "\n",
    "    How to use:\n",
    "    Just put it on top of an RNN Layer (GRU/LSTM/SimpleRNN) with return_sequences=True.\n",
    "    The dimensions are inferred based on the output shape of the RNN.\n",
    "\n",
    "    Note: The layer has been tested with Keras 2.0.6\n",
    "\n",
    "    Example:\n",
    "        model.add(LSTM(64, return_sequences=True))\n",
    "        model.add(AttentionWithContext())\n",
    "        # next add a Dense layer (for classification/regression) or whatever...\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 W_regularizer=None, u_regularizer=None, b_regularizer=None,\n",
    "                 W_constraint=None, u_constraint=None, b_constraint=None,\n",
    "                 bias=True, **kwargs):\n",
    "\n",
    "        self.supports_masking = True\n",
    "        self.init = initializers.get('glorot_uniform')\n",
    "\n",
    "        self.W_regularizer = regularizers.get(W_regularizer)\n",
    "        self.u_regularizer = regularizers.get(u_regularizer)\n",
    "        self.b_regularizer = regularizers.get(b_regularizer)\n",
    "\n",
    "        self.W_constraint = constraints.get(W_constraint)\n",
    "        self.u_constraint = constraints.get(u_constraint)\n",
    "        self.b_constraint = constraints.get(b_constraint)\n",
    "\n",
    "        self.bias = bias\n",
    "        super(AttentionWithContext, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "\n",
    "        self.W = self.add_weight((input_shape[-1], input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 regularizer=self.W_regularizer,\n",
    "                                 constraint=self.W_constraint)\n",
    "        if self.bias:\n",
    "            self.b = self.add_weight((input_shape[-1],),\n",
    "                                     initializer='zero',\n",
    "                                     name='{}_b'.format(self.name),\n",
    "                                     regularizer=self.b_regularizer,\n",
    "                                     constraint=self.b_constraint)\n",
    "\n",
    "        self.u = self.add_weight((input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_u'.format(self.name),\n",
    "                                 regularizer=self.u_regularizer,\n",
    "                                 constraint=self.u_constraint)\n",
    "\n",
    "        super(AttentionWithContext, self).build(input_shape)\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        # do not pass the mask to the next layers\n",
    "        return None\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        uit = dot_product(x, self.W)\n",
    "\n",
    "        if self.bias:\n",
    "            uit += self.b\n",
    "\n",
    "        uit = K.tanh(uit)\n",
    "        ait = dot_product(uit, self.u)\n",
    "\n",
    "        a = K.exp(ait)\n",
    "\n",
    "        # apply mask after the exp. will be re-normalized next\n",
    "        if mask is not None:\n",
    "            # Cast the mask to floatX to avoid float64 upcasting in theano\n",
    "            a *= K.cast(mask, K.floatx())\n",
    "\n",
    "        # in some cases especially in the early stages of training the sum may be almost zero\n",
    "        # and this results in NaN's. A workaround is to add a very small positive number  to the sum.\n",
    "        # a /= K.cast(K.sum(a, axis=1, keepdims=True), K.floatx())\n",
    "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "\n",
    "        a = K.expand_dims(a)\n",
    "        weighted_input = x * a\n",
    "        return K.sum(weighted_input, axis=1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0], input_shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
