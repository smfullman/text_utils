{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier, RidgeClassifierCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, VotingClassifier\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, roc_auc_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import LdaMulticore\n",
    "from gensim import corpora\n",
    "from gensim.matutils import sparse2full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For dockers + ensembles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.environ['JOBLIB_TEMP_FOLDER'] = '../data/tmp/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 3)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('data/labeledTrainData.tsv', sep='\\t')\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5814_8</td>\n",
       "      <td>1</td>\n",
       "      <td>With all this stuff going down at the moment w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2381_9</td>\n",
       "      <td>1</td>\n",
       "      <td>\\The Classic War of the Worlds\\\" by Timothy Hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7759_3</td>\n",
       "      <td>0</td>\n",
       "      <td>The film starts with a manager (Nicholas Bell)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3630_4</td>\n",
       "      <td>0</td>\n",
       "      <td>It must be assumed that those who praised this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9495_8</td>\n",
       "      <td>1</td>\n",
       "      <td>Superbly trashy and wondrously unpretentious 8...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  sentiment                                             review\n",
       "0  5814_8          1  With all this stuff going down at the moment w...\n",
       "1  2381_9          1  \\The Classic War of the Worlds\\\" by Timothy Hi...\n",
       "2  7759_3          0  The film starts with a manager (Nicholas Bell)...\n",
       "3  3630_4          0  It must be assumed that those who praised this...\n",
       "4  9495_8          1  Superbly trashy and wondrously unpretentious 8..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 2)\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv('data/testData.tsv', sep='\\t')\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count_vec = CountVectorizer(ngram_range=(1,2), \n",
    "                            min_df=5,\n",
    "                            max_df=0.9,\n",
    "                            strip_accents='unicode',\n",
    "                            max_features=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf_vec = TfidfVectorizer(ngram_range=(1,2), \n",
    "                            min_df=5,\n",
    "                            max_df=0.9,\n",
    "                            strip_accents='unicode',\n",
    "                            use_idf=1,\n",
    "                            smooth_idf=1,\n",
    "                            sublinear_tf=1,\n",
    "                            max_features=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.9, max_features=None, min_df=5,\n",
       "        ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
       "        strip_accents='unicode', token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vec.fit(train[\"review\"].fillna(\"\").values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_count = count_vec.transform(train[\"review\"].fillna(\"\").values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "(25000, 156877)\n"
     ]
    }
   ],
   "source": [
    "print(type(X_count))\n",
    "print(X_count.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.9, max_features=None, min_df=5,\n",
       "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=1,\n",
       "        stop_words=None, strip_accents='unicode', sublinear_tf=1,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=1,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vec.fit(train[\"review\"].fillna(\"\").values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_tfidf = tfidf_vec.transform(train[\"review\"].fillna(\"\").values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "(25000, 156877)\n"
     ]
    }
   ],
   "source": [
    "print(type(X_tfidf))\n",
    "print(X_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = train['sentiment'].as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000,)\n"
     ]
    }
   ],
   "source": [
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Topic Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary.load('models/topic_dict.dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lda = LdaMulticore.load('models/topic_lda_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_row_count = train['review'].shape[0]\n",
    "vector_size = lda.num_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['review_topic_vector'] = train['review'].apply(lambda x: lda[dictionary.doc2bow(x.lower().split(\" \"))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_lda_matrix = np.reshape(np.concatenate(train['review_topic_vector']\n",
    "                                         .apply(lambda x: sparse2full(x, vector_size))\n",
    "                                         .as_matrix(), axis=0), (text_row_count,vector_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test['review_topic_vector'] = test['review'].apply(lambda x: lda[dictionary.doc2bow(x.lower().split(\" \"))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_lda_matrix_test = np.reshape(np.concatenate(test['review_topic_vector']\n",
    "                                         .apply(lambda x: sparse2full(x, vector_size))\n",
    "                                         .as_matrix(), axis=0), (test['review'].shape[0],vector_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concat Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_count_concat = hstack((X_count, X_lda_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_tfidf_concat = hstack((X_tfidf, X_lda_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_count_train, X_count_val, y_count_train, y_count_val = train_test_split(X_count_concat, y, test_size=0.1, random_state=2481632)\n",
    "X_tfidf_train, X_tfidf_val, y_tfidf_train, y_tfidf_val = train_test_split(X_tfidf_concat, y, test_size=0.1, random_state=2481632)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_count_test = count_vec.transform(test['review'].fillna(\"\").values)\n",
    "X_tfidf_test = tfidf_vec.transform(test['review'].fillna(\"\").values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_count_test = hstack((X_count_test, X_lda_matrix_test))\n",
    "X_tfidf_test = hstack((X_tfidf_test, X_lda_matrix_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lm_logit = LogisticRegression(penalty='l2',\n",
    "                              C=1.0,\n",
    "                              class_weight=None,\n",
    "                              random_state=42,\n",
    "                              solver='liblinear',\n",
    "                              max_iter=1000,\n",
    "                              verbose=1,\n",
    "                              n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=1000, multi_class='ovr', n_jobs=-1,\n",
       "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "          verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_logit.fit(X_count_train, y_count_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_val_hat = lm_logit.predict(X_count_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9012\n",
      "[[1121  126]\n",
      " [ 121 1132]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.90      0.90      1247\n",
      "          1       0.90      0.90      0.90      1253\n",
      "\n",
      "avg / total       0.90      0.90      0.90      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_count_val, y_val_hat))\n",
    "print(confusion_matrix(y_count_val, y_val_hat))\n",
    "print(classification_report(y_count_val, y_val_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lm_logit_tfidf = LogisticRegression(penalty='l2',\n",
    "                              C=1.0,\n",
    "                              class_weight=None,\n",
    "                              random_state=42,\n",
    "                              solver='liblinear',\n",
    "                              max_iter=1000,\n",
    "                              verbose=1,\n",
    "                              n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=1000, multi_class='ovr', n_jobs=-1,\n",
       "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "          verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_logit_tfidf.fit(X_tfidf_train, y_tfidf_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_tfidf_val_hat = lm_logit_tfidf.predict(X_tfidf_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8864\n",
      "[[1093  154]\n",
      " [ 130 1123]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.88      0.89      1247\n",
      "          1       0.88      0.90      0.89      1253\n",
      "\n",
      "avg / total       0.89      0.89      0.89      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_tfidf_val, y_tfidf_val_hat))\n",
    "print(confusion_matrix(y_tfidf_val, y_tfidf_val_hat))\n",
    "print(classification_report(y_tfidf_val, y_tfidf_val_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lm_ridge = RidgeClassifierCV(alphas=(0.1, 0.5, 1.0, 5.0, 10.0), \n",
    "                             cv=5,\n",
    "                             class_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RidgeClassifierCV(alphas=(0.1, 0.5, 1.0, 5.0, 10.0), class_weight=None, cv=5,\n",
       "         fit_intercept=True, normalize=False, scoring=None)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_ridge.fit(X_count_train, y_count_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_ridge.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_ridge_val_hat = lm_ridge.predict(X_count_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8916\n",
      "[[1105  142]\n",
      " [ 129 1124]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.89      0.89      1247\n",
      "          1       0.89      0.90      0.89      1253\n",
      "\n",
      "avg / total       0.89      0.89      0.89      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_count_val, y_ridge_val_hat))\n",
    "print(confusion_matrix(y_count_val, y_ridge_val_hat))\n",
    "print(classification_report(y_count_val, y_ridge_val_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lm_ridge_single = RidgeClassifier(alpha=10.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb = MultinomialNB(alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.5, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.fit(X_count_train, y_count_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_nb_val_hat = nb.predict(X_count_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8688\n",
      "[[1111  136]\n",
      " [ 192 1061]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.89      0.87      1247\n",
      "          1       0.89      0.85      0.87      1253\n",
      "\n",
      "avg / total       0.87      0.87      0.87      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_count_val, y_nb_val_hat))\n",
    "print(confusion_matrix(y_count_val, y_nb_val_hat))\n",
    "print(classification_report(y_count_val, y_nb_val_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NB-SVM Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relevant Paper: https://nlp.stanford.edu/pubs/sidaw12_simple_sentiment.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_prob(X_vectors, y_i, y):\n",
    "    p = X_vectors[y==y_i].sum(0)\n",
    "    return (p+1) / ((y==y_i).sum()+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r = np.log(get_prob(X_count_train, 1, y_count_train) / get_prob(X_count_train, 0, y_count_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 156927)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ -1.95211291e-01,  -8.46764574e-01,   5.33285943e-04, ...,\n",
       "           9.21893692e-01,  -6.42171516e-01,  -6.84214224e-01]])"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = LogisticRegression(C=4, dual=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_nb = X_count_train.multiply(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=4, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.fit(x_nb, y_count_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_hat = m.predict(X_count_val.multiply(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9172\n",
      "[[1133  114]\n",
      " [  93 1160]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.91      0.92      1247\n",
      "          1       0.91      0.93      0.92      1253\n",
      "\n",
      "avg / total       0.92      0.92      0.92      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_count_val, y_hat))\n",
    "print(confusion_matrix(y_count_val, y_hat))\n",
    "print(classification_report(y_count_val, y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=300, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=300, n_jobs=-1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(X_count_train, y_count_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8644\n",
      "[[1067  180]\n",
      " [ 159 1094]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.86      0.86      1247\n",
      "          1       0.86      0.87      0.87      1253\n",
      "\n",
      "avg / total       0.86      0.86      0.86      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_count_val, rf.predict(X_count_val)))\n",
    "print(confusion_matrix(y_count_val, rf.predict(X_count_val)))\n",
    "print(classification_report(y_count_val, rf.predict(X_count_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gbc = GradientBoostingClassifier(n_estimators=200, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3551            3.46m\n",
      "         2           1.3286            3.02m\n",
      "         3           1.3051            2.91m\n",
      "         4           1.2839            2.83m\n",
      "         5           1.2660            2.78m\n",
      "         6           1.2488            2.72m\n",
      "         7           1.2332            2.68m\n",
      "         8           1.2197            2.65m\n",
      "         9           1.2071            2.60m\n",
      "        10           1.1950            2.58m\n",
      "        20           1.1073            2.34m\n",
      "        30           1.0485            2.20m\n",
      "        40           1.0033            2.09m\n",
      "        50           0.9659            1.96m\n",
      "        60           0.9349            1.84m\n",
      "        70           0.9087            1.70m\n",
      "        80           0.8842            1.56m\n",
      "        90           0.8628            1.43m\n",
      "       100           0.8433            1.30m\n",
      "       200           0.7109            0.00s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "              presort='auto', random_state=None, subsample=1.0, verbose=1,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbc.fit(X_count_train, y_count_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8416\n",
      "[[1010  237]\n",
      " [ 159 1094]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.81      0.84      1247\n",
      "          1       0.82      0.87      0.85      1253\n",
      "\n",
      "avg / total       0.84      0.84      0.84      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_count_val, gbc.predict(X_count_val)))\n",
    "print(confusion_matrix(y_count_val, gbc.predict(X_count_val)))\n",
    "print(classification_report(y_count_val, gbc.predict(X_count_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vote_m = VotingClassifier([('lm_ridge_single',lm_ridge_single), ('rf',rf), ('gbc',gbc)],\n",
    "                          voting='hard',\n",
    "                          n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3551            6.53m\n",
      "         2           1.3286            6.37m\n",
      "         3           1.3051            6.49m\n",
      "         4           1.2839            6.42m\n",
      "         5           1.2660            6.54m\n",
      "         6           1.2488            6.30m\n",
      "         7           1.2332            6.42m\n",
      "         8           1.2197            6.27m\n",
      "         9           1.2071            6.15m\n",
      "        10           1.1950            6.13m\n",
      "        20           1.1073            5.39m\n",
      "        30           1.0485            4.22m\n",
      "        40           1.0033            3.51m\n",
      "        50           0.9659            3.02m\n",
      "        60           0.9349            2.64m\n",
      "        70           0.9087            2.32m\n",
      "        80           0.8842            2.06m\n",
      "        90           0.8628            1.83m\n",
      "       100           0.8433            1.61m\n",
      "       200           0.7109            0.00s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lm_ridge_single', RidgeClassifier(alpha=10.0, class_weight=None, copy_X=True,\n",
       "        fit_intercept=True, max_iter=None, normalize=False,\n",
       "        random_state=None, solver='auto', tol=0.001)), ('rf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "          ...      presort='auto', random_state=None, subsample=1.0, verbose=1,\n",
       "              warm_start=False))],\n",
       "         flatten_transform=None, n_jobs=-1, voting='hard', weights=None)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vote_m.fit(X_count_train, y_count_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8824\n",
      "[[1075  172]\n",
      " [ 122 1131]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.86      0.88      1247\n",
      "          1       0.87      0.90      0.88      1253\n",
      "\n",
      "avg / total       0.88      0.88      0.88      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_count_val, vote_m.predict(X_count_val)))\n",
    "print(confusion_matrix(y_count_val, vote_m.predict(X_count_val)))\n",
    "print(classification_report(y_count_val, vote_m.predict(X_count_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
